{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMuDJpAc0YNIEb9CRxKv/sG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markcam1/machine-learning-00/blob/main/Final_Project_Tech27_load-and-feature-engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering and Predictive Modeling of S&P 500 Stock Price Behaviors\n",
        "\n",
        "Final Project Tech 27"
      ],
      "metadata": {
        "id": "Cq23a7CRPuea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# S&P 500 Dataset - Complete Data Review\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set display options for better output\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "print(\"S&P 500 DATASET REVIEW\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
      ],
      "metadata": {
        "id": "FbMRC2czYOrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and Review Data"
      ],
      "metadata": {
        "id": "ji0fuqlFaWw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 1. SETUP AND DOWNLOAD\n",
        "# =============================================================================\n",
        "\n",
        "# For Google Colab - set up Kaggle credentials\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    import os\n",
        "    os.environ['KAGGLE_USERNAME'] = userdata.get('KAGGLE_USERNAME')\n",
        "    os.environ['KAGGLE_KEY'] = userdata.get('KAGGLE_KEY')\n",
        "    print(\"Running on Google Colab - Kaggle credentials loaded\")\n",
        "    colab_environment = True\n",
        "except:\n",
        "    print(\"Running on Local env\")\n",
        "    colab_environment = False\n",
        "\n",
        "# Install kaggle\n",
        "if colab_environment:\n",
        "    !pip install kaggle -q\n",
        "\n",
        "# Download the dataset\n",
        "print(\"Download the dataset...\")\n",
        "dataset_name = \"andrewmvd/sp-500-stocks\"\n",
        "\n",
        "if colab_environment:\n",
        "    !kaggle datasets download -d {dataset_name} -p /content/ --unzip -q\n",
        "    data_path = \"/content/\"\n",
        "else:\n",
        "    # For Jupyter notebook\n",
        "    !kaggle datasets download -d {dataset_name} --unzip -q\n",
        "    data_path = \"./\"\n",
        "\n",
        "print(\"Dataset downloaded successfully!\")"
      ],
      "metadata": {
        "id": "IWqmuHvJZ3CX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21eea0e6-a5f3-4ad6-cf13-7c741f68eaf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on Google Colab - Kaggle credentials loaded\n",
            "\n",
            "DOWNLOADING DATASET...\n",
            "Dataset URL: https://www.kaggle.com/datasets/andrewmvd/sp-500-stocks\n",
            "License(s): CC0-1.0\n",
            "Dataset downloaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### File Exploration"
      ],
      "metadata": {
        "id": "yMCbL-nqdqh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################\n",
        "# FILE EXPLORATION\n",
        "\n",
        "print(f\"\\FILES IN DATASET:\")\n",
        "\n",
        "import os\n",
        "csv_files = []\n",
        "for file in os.listdir(data_path):\n",
        "    if file.endswith('.csv'):\n",
        "        file_path = os.path.join(data_path, file)\n",
        "        file_size = os.path.getsize(file_path) / 1024 / 1024  # MB\n",
        "        csv_files.append(file)\n",
        "        print(f\"  {file}\")\n",
        "        print(f\"   Size: {file_size:.2f} MB\")\n",
        "\n",
        "        # Get 3 rows\n",
        "        temp_df = pd.read_csv(file_path, nrows=3)\n",
        "        print(f\"   Columns: {list(temp_df.columns)}\")\n",
        "        print(f\"   Sample shape: {temp_df.shape}\")\n",
        "        print()\n"
      ],
      "metadata": {
        "id": "zKRopH7Ialf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9fad432-1280-4ddc-f420-7b49dc01ff09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“ FILES IN DATASET:\n",
            "------------------------------\n",
            "ðŸ“„ sp500_stocks.csv\n",
            "   Size: 91.85 MB\n",
            "   Columns: ['Date', 'Symbol', 'Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
            "   Sample shape: (3, 8)\n",
            "\n",
            "ðŸ“„ sp500_index.csv\n",
            "   Size: 0.05 MB\n",
            "   Columns: ['Date', 'S&P500']\n",
            "   Sample shape: (3, 2)\n",
            "\n",
            "ðŸ“„ sp500_companies.csv\n",
            "   Size: 0.77 MB\n",
            "   Columns: ['Exchange', 'Symbol', 'Shortname', 'Longname', 'Sector', 'Industry', 'Currentprice', 'Marketcap', 'Ebitda', 'Revenuegrowth', 'City', 'State', 'Country', 'Fulltimeemployees', 'Longbusinesssummary', 'Weight']\n",
            "   Sample shape: (3, 16)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######################\n",
        "# 3. LOAD MAIN DATASET\n",
        "######################\n",
        "\n",
        "print(\"LOADING MAIN DATASET:\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Load the main stocks file\n",
        "main_file = \"sp500_stocks.csv\"\n",
        "if main_file in csv_files:\n",
        "    df_sp500_kaggle = pd.read_csv(os.path.join(data_path, main_file))\n",
        "    print(f\"Loaded {main_file}\")\n",
        "else:\n",
        "    # If different name, load the first CSV file\n",
        "    df_sp500_kaggle = pd.read_csv(os.path.join(data_path, csv_files[0]))\n",
        "    main_file = csv_files[0]\n",
        "    print(f\"Loaded {csv_files[0]} (main file)\")"
      ],
      "metadata": {
        "id": "dykQWtUIanh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load MAIN File (re)"
      ],
      "metadata": {
        "id": "P7p0aao0iyU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# load dataset\n",
        "\n",
        "print(f\"\\nDATASET OVERVIEW:\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"Shape: {df_sp500_kaggle.shape[0]:,} rows Ã— {df_sp500_kaggle.shape[1]} columns\")\n",
        "print(f\"Memory Usage: {df_sp500_kaggle.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")\n",
        "print(f\"Date Range: {df_sp500_kaggle['Date'].min()} to {df_sp500_kaggle['Date'].max()}\")\n",
        "\n",
        "# Convert Date column\n",
        "df_sp500_kaggle['Date'] = pd.to_datetime(df_sp500_kaggle['Date'])\n",
        "date_range_days = (df_sp500_kaggle['Date'].max() - df_sp500_kaggle['Date'].min()).days\n",
        "print(f\"Total Days Covered: {date_range_days:,} days\")\n",
        "print(f\"Unique Trading Days: {df_sp500_kaggle['Date'].nunique():,}\")"
      ],
      "metadata": {
        "id": "nD2VwO1ja4q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########################################\n",
        "# Use S&P symbols to query Yahoo finance\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# load symbols from sp500_companies.csv\n",
        "companies = pd.read_csv('sp500_companies.csv')\n",
        "symbols = companies['Symbol'].tolist()\n",
        "\n",
        "# define date range\n",
        "start_date = '2010-01-01'\n",
        "end_date = datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "# Fetch data\n",
        "data = yf.download(symbols, start=start_date, end=end_date, group_by='ticker', progress=True)"
      ],
      "metadata": {
        "id": "jJNPiSK1q1PZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################\n",
        "# Kaggle data reshape\n",
        "\n",
        "Reshape to long format (like Kaggle: Date, Symbol, Open, High, Low, Close, Adj Close, Volume)\n",
        "df_list = []\n",
        "for symbol in symbols:\n",
        "    temp = data[symbol].copy()\n",
        "    temp['Symbol'] = symbol\n",
        "    temp = temp.reset_index()[['Date', 'Symbol', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
        "    df_list.append(temp)\n",
        "df = pd.concat(df_list, ignore_index=True)\n",
        "df['Date'] = pd.to_datetime(df['Date'])"
      ],
      "metadata": {
        "id": "p1JXh2strWfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########################\n",
        "# column analysis\n",
        "\n",
        "print(f\"\\COLUMN DETAILS:\")\n",
        "\n",
        "# Column info table\n",
        "column_info = pd.DataFrame({\n",
        "    'Column': df.columns,\n",
        "    'Data Type': df.dtypes,\n",
        "    'Non-Null Count': df.count(),\n",
        "    'Null Count': df.isnull().sum(),\n",
        "    'Null %': (df.isnull().sum() / len(df) * 100).round(2),\n",
        "    'Unique Values': [df[col].nunique() for col in df.columns],\n",
        "    'Memory Usage (KB)': (df.memory_usage(deep=True, index=False) / 1024).round(2),\n",
        "    'Memory Usage (GB)': (df.memory_usage(deep=True, index=False) / (1024 ** 3)).round(4)\n",
        "})\n",
        "\n",
        "print(column_info.to_string(index=False))\n"
      ],
      "metadata": {
        "id": "9ZCOjXaJbQcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handle Missing Values"
      ],
      "metadata": {
        "id": "kRTx4xjYha1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Report missing values\n",
        "print(\"Missing values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "price_cols = ['Open', 'High', 'Low', 'Close']\n",
        "\n",
        "# Calculate % missing volume per stock\n",
        "missing_pct_volume = df.groupby('Symbol')['Volume'].apply(lambda x: x.isna().mean())\n",
        "\n",
        "# Get list of stocks with > 10% missing volume\n",
        "stocks_with_missing_volume_10pct = missing_pct_volume[missing_pct_volume > 0.1].index.tolist()\n",
        "print(f\"\\nStocks Missing volume > 10%: {stocks_with_missing_volume_10pct}\")\n",
        "print(f\"\\nNumber of stocks Missing volume > 10%: {len(stocks_with_missing_volume_10pct)}\")\n",
        "\n",
        "# Get list of stocks with > 05% missing volume\n",
        "stocks_with_missing_volume_05pct = missing_pct_volume[missing_pct_volume > 0.05].index.tolist()\n",
        "print(f\"\\nStocks Missing volume > 05%: {stocks_with_missing_volume_05pct}\")\n",
        "print(f\"\\nNumber of stocks Missing volume > 05%: {len(stocks_with_missing_volume_05pct)}\")\n",
        "\n",
        "\n",
        "# Drop stocks with excessive missing data\n",
        "# Columns to review for missing data\n",
        "price_cols = ['Open', 'High', 'Low', 'Close']\n",
        "# find missing data in price columns and average across each stock\n",
        "missing_pct_stock_px = df.groupby('Symbol').apply(lambda x: x[price_cols].isnull().mean()).mean(axis=1)\n",
        "# display(missing_pct_stock_px)\n",
        "\n",
        "# find list of stocks missing more than 10%\n",
        "stocks_to_drop = missing_pct_stock_px[missing_pct_stock_px > 0.1].index\n",
        "print(f\"\\nstocks_to_drop: {stocks_to_drop}\")\n",
        "print(f\"\\nNumber of stocks to drop: {len(stocks_to_drop)}\")\n",
        "\n",
        "# # 05%\n",
        "stocks_to_drop_05pct = missing_pct_stock_px[missing_pct_stock_px > 0.05].index\n",
        "print(f\"\\nstocks_to_drop_05pct: {stocks_to_drop_05pct}\")\n",
        "print(f\"\\nNumber of stocks to drop: {len(stocks_to_drop_05pct)}\")\n",
        "\n",
        "df = df[~df['Symbol'].isin(stocks_to_drop_05pct)]"
      ],
      "metadata": {
        "id": "JVy18xVzheOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Report missing values\n",
        "print(\"Missing values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Find stocks that have any missing Volume\n",
        "stocks_to_drop_no_vol = df.groupby('Symbol')['Volume'].apply(lambda x: x.isna().any())\n",
        "stocks_to_drop_no_vol = stocks_to_drop_no_vol[stocks_to_drop_no_vol].index.tolist()\n",
        "\n",
        "print(\"Dropping stocks (any missing Volume):\", stocks_to_drop_no_vol)\n",
        "\n",
        "# Drop them from the dataframe\n",
        "df = df[~df['Symbol'].isin(stocks_to_drop_no_vol)]\n",
        "\n",
        "# Verify\n",
        "print(\"Missing values:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "_fiNjsIx40ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Cleaned Stocks to File"
      ],
      "metadata": {
        "id": "Nc-a_N6tFbW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save cleaned dataset\n",
        "df.to_csv('cleaned_sp500_stocks.csv', index=False)\n",
        "print(\"Cleaned dataset saved.\")"
      ],
      "metadata": {
        "id": "_lv7Ybsph8oQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature engineering:"
      ],
      "metadata": {
        "id": "bc13knH2-5Ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount your Google Drive again\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Imports\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/cleaned_sp500_stocks.csv')\n",
        "\n",
        "# review\n",
        "print(\"File loaded successfully!\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cfNOaPn-cTF",
        "outputId": "10147684-8d60-44d5-de8b-e51420de5a9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File loaded successfully!\n",
            "         Date Symbol      Open      High       Low     Close       Volume  \\\n",
            "0  2010-01-04   AAPL  6.407195  6.439316  6.375674  6.424606  493729600.0   \n",
            "1  2010-01-05   AAPL  6.442317  6.472037  6.401789  6.435712  601904800.0   \n",
            "2  2010-01-06   AAPL  6.435712  6.461229  6.326739  6.333344  552160000.0   \n",
            "3  2010-01-07   AAPL  6.356760  6.364265  6.275706  6.321636  477131200.0   \n",
            "4  2010-01-08   AAPL  6.313230  6.364264  6.276006  6.363664  447610800.0   \n",
            "\n",
            "   Year  \n",
            "0  2010  \n",
            "1  2010  \n",
            "2  2010  \n",
            "3  2010  \n",
            "4  2010  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Report missing values\n",
        "print(\"Missing values:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV__Oy-N-25L",
        "outputId": "05946315-1aa4-43b0-ba7d-e360de2f592d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values after first drops:\n",
            "Date      0\n",
            "Symbol    0\n",
            "Open      0\n",
            "High      0\n",
            "Low       0\n",
            "Close     0\n",
            "Volume    0\n",
            "Year      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Return\n",
        "\n",
        "Open-to-Close intraday return:\n",
        "* Measures how much the stock moved within the day (from opening price to closing price).\n",
        "* Captures intraday behavior â€” how bullish or bearish the trading day was."
      ],
      "metadata": {
        "id": "t369gC5w_iOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################\n",
        "# 'Return' with (Close - Open) / Open\n",
        "df['Return'] = (df['Close'] - df['Open']) / df['Open']"
      ],
      "metadata": {
        "id": "CnnNNz4r_QLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdYQxk5b_YPN",
        "outputId": "dfecabcc-9ab9-4bd6-c416-e96a5f3fc433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1679818 entries, 0 to 1679817\n",
            "Data columns (total 9 columns):\n",
            " #   Column  Non-Null Count    Dtype  \n",
            "---  ------  --------------    -----  \n",
            " 0   Date    1679818 non-null  object \n",
            " 1   Symbol  1679818 non-null  object \n",
            " 2   Open    1679818 non-null  float64\n",
            " 3   High    1679818 non-null  float64\n",
            " 4   Low     1679818 non-null  float64\n",
            " 5   Close   1679818 non-null  float64\n",
            " 6   Volume  1679818 non-null  float64\n",
            " 7   Year    1679818 non-null  int64  \n",
            " 8   Return  1679818 non-null  float64\n",
            "dtypes: float64(6), int64(1), object(2)\n",
            "memory usage: 115.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Annualized Volatility"
      ],
      "metadata": {
        "id": "e3BjDg92F9-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort by Symbol and Date\n",
        "df = df.sort_values(['Symbol', 'Date']).reset_index(drop=True)\n",
        "\n",
        "# Compute annualized vol per stock\n",
        "Annual_Vol = df.groupby('Symbol')['Return'].transform(lambda x: x.std() * np.sqrt(252))\n",
        "\n",
        "# Add new column\n",
        "df['Annual_Vol'] = Annual_Vol\n",
        "\n",
        "print(df[['Date', 'Symbol', 'Return', 'Annual_Vol']].head(20))\n",
        "\n",
        "print(\"Annualized Volatility per Symbol:\")\n",
        "print(Annual_Vol.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJeh5OmW5D02",
        "outputId": "32c2faf1-4e9d-43d6-ae61-482df76b5399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Date Symbol    Return  Annual_Vol\n",
            "0   2010-01-04      A -0.002867     0.23301\n",
            "1   2010-01-05      A -0.008010     0.23301\n",
            "2   2010-01-06      A  0.000000     0.23301\n",
            "3   2010-01-07      A  0.000975     0.23301\n",
            "4   2010-01-08      A  0.005222     0.23301\n",
            "5   2010-01-11      A -0.001943     0.23301\n",
            "6   2010-01-12      A -0.003599     0.23301\n",
            "7   2010-01-13      A  0.007220     0.23301\n",
            "8   2010-01-14      A  0.018307     0.23301\n",
            "9   2010-01-15      A -0.025304     0.23301\n",
            "10  2010-01-19      A  0.014493     0.23301\n",
            "11  2010-01-20      A  0.003275     0.23301\n",
            "12  2010-01-21      A -0.015484     0.23301\n",
            "13  2010-01-22      A -0.038880     0.23301\n",
            "14  2010-01-25      A  0.001020     0.23301\n",
            "15  2010-01-26      A -0.002724     0.23301\n",
            "16  2010-01-27      A -0.001027     0.23301\n",
            "17  2010-01-28      A -0.015105     0.23301\n",
            "18  2010-01-29      A -0.031110     0.23301\n",
            "19  2010-02-01      A  0.034446     0.23301\n",
            "Annualized Volatility per Symbol:\n",
            "0    0.23301\n",
            "1    0.23301\n",
            "2    0.23301\n",
            "3    0.23301\n",
            "4    0.23301\n",
            "Name: Return, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Report missing values\n",
        "print(\"Missing values after adding Annualized Volatility:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34182e56-db59-4f63-c266-69e39d6a9120",
        "id": "Ob4vwgg6C6ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values after adding Annualized Volatility:\n",
            "Date          0\n",
            "Symbol        0\n",
            "Open          0\n",
            "High          0\n",
            "Low           0\n",
            "Close         0\n",
            "Volume        0\n",
            "Year          0\n",
            "Return        0\n",
            "Annual_Vol    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rolling 30 Day Volatility"
      ],
      "metadata": {
        "id": "QT0aILkTGHNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Roll_Vol_30d'] = (\n",
        "    df.groupby('Symbol')['Return']\n",
        "      .transform(lambda x: x.rolling(window=30, min_periods=5).std() * np.sqrt(252))\n",
        ")\n",
        "\n",
        "print(df[['Date', 'Symbol', 'Return', 'Roll_Vol_30d']].head(40))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euSCTmgtATc8",
        "outputId": "d60266c2-a3f2-4949-87b6-015f320345e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Date Symbol    Return  Roll_Vol_30d\n",
            "0   2010-01-04      A -0.002867           NaN\n",
            "1   2010-01-05      A -0.008010           NaN\n",
            "2   2010-01-06      A  0.000000           NaN\n",
            "3   2010-01-07      A  0.000975           NaN\n",
            "4   2010-01-08      A  0.005222      0.077859\n",
            "5   2010-01-11      A -0.001943      0.069944\n",
            "6   2010-01-12      A -0.003599      0.065582\n",
            "7   2010-01-13      A  0.007220      0.077847\n",
            "8   2010-01-14      A  0.018307      0.122781\n",
            "9   2010-01-15      A -0.025304      0.178262\n",
            "10  2010-01-19      A  0.014493      0.184658\n",
            "11  2010-01-20      A  0.003275      0.176554\n",
            "12  2010-01-21      A -0.015484      0.183352\n",
            "13  2010-01-22      A -0.038880      0.239618\n",
            "14  2010-01-25      A  0.001020      0.231588\n",
            "15  2010-01-26      A -0.002724      0.223739\n",
            "16  2010-01-27      A -0.001027      0.216770\n",
            "17  2010-01-28      A -0.015105      0.215198\n",
            "18  2010-01-29      A -0.031110      0.231925\n",
            "19  2010-02-01      A  0.034446      0.265692\n",
            "20  2010-02-02      A  0.009583      0.262638\n",
            "21  2010-02-03      A  0.005104      0.257582\n",
            "22  2010-02-04      A -0.007850      0.252376\n",
            "23  2010-02-05      A  0.008993      0.249555\n",
            "24  2010-02-08      A -0.000342      0.244349\n",
            "25  2010-02-09      A -0.004064      0.239514\n",
            "26  2010-02-10      A -0.007128      0.235403\n",
            "27  2010-02-11      A  0.003761      0.231672\n",
            "28  2010-02-12      A -0.021860      0.234987\n",
            "29  2010-02-16      A  0.000331      0.231054\n",
            "30  2010-02-17      A  0.008893      0.233388\n",
            "31  2010-02-18      A  0.013412      0.236900\n",
            "32  2010-02-19      A  0.011673      0.239888\n",
            "33  2010-02-22      A -0.004474      0.240020\n",
            "34  2010-02-23      A -0.007719      0.239955\n",
            "35  2010-02-24      A  0.008395      0.241692\n",
            "36  2010-02-25      A  0.008106      0.243084\n",
            "37  2010-02-26      A  0.009304      0.243761\n",
            "38  2010-03-01      A  0.020999      0.245712\n",
            "39  2010-03-02      A  0.011250      0.236587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Report missing values\n",
        "print(\"Missing values after adding 30 Day rolling Volatility:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "304862a1-fe3d-49dd-fa64-4ee883dcc626",
        "id": "CuoqCfW8GFaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values after adding 30 Day rolling Volatility:\n",
            "Date               0\n",
            "Symbol             0\n",
            "Open               0\n",
            "High               0\n",
            "Low                0\n",
            "Close              0\n",
            "Volume             0\n",
            "Year               0\n",
            "Return             0\n",
            "Annual_Vol         0\n",
            "Roll_Vol_30d    1708\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Returns: Lagged, Close-to-close"
      ],
      "metadata": {
        "id": "jf1TwEPfGsX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Close to close return or daily return\n",
        "df['Return_Daily'] = df['Close'].pct_change()\n"
      ],
      "metadata": {
        "id": "pKOIpLBfHd8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lagged Returns (Return_t-1, Return_t-2)\n",
        "df['Return_t-1'] = df.groupby('Symbol')['Return'].shift(1)\n",
        "df['Return_t-2'] = df.groupby('Symbol')['Return'].shift(2)"
      ],
      "metadata": {
        "id": "goLpRezJIP41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Report missing values\n",
        "print(\"Missing values after adding Return lagged, close2close:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9kcUfqlIet9",
        "outputId": "55f6f927-3856-4749-f026-bfb28a46a94f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values after adding Return lagged, close2close:\n",
            "Date               0\n",
            "Symbol             0\n",
            "Open               0\n",
            "High               0\n",
            "Low                0\n",
            "Close              0\n",
            "Volume             0\n",
            "Year               0\n",
            "Return             0\n",
            "Annual_Vol         0\n",
            "Roll_Vol_30d    1708\n",
            "Return_Daily       1\n",
            "Return_t-1       427\n",
            "Return_t-2       854\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xbKUKP1iInHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save cleaned dataset\n",
        "df.to_csv('/content/drive/MyDrive/sp500_stocks_feature-eng.csv', index=False)\n",
        "\n",
        "print(\"Complete dataset saved to your Google Drive.\")\n"
      ],
      "metadata": {
        "id": "VD30sN-BILBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/sp500_stocks_feature-eng.csv')\n",
        "\n",
        "# reviw\n",
        "print(\"sp500_stocks_feature-eng.csv loaded successfully!\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "MwieAKZ0ObKO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63feaf11-dc5a-4e25-bef4-15e8a39d58f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "sp500_stocks_feature-eng.csv loaded successfully!\n",
            "         Date Symbol       Open       High        Low      Close     Volume  \\\n",
            "0  2010-01-04      A  19.988936  20.141767  19.823370  19.931625  3815561.0   \n",
            "1  2010-01-05      A  19.874313  19.880681  19.587755  19.715115  4186031.0   \n",
            "2  2010-01-06      A  19.645065  19.740584  19.587753  19.645065  3243779.0   \n",
            "3  2010-01-07      A  19.600485  19.625958  19.422184  19.619591  3095172.0   \n",
            "4  2010-01-08      A  19.511342  19.645069  19.358512  19.613228  3733918.0   \n",
            "\n",
            "   Year    Return  Annual_Vol  Roll_Vol_30d  Return_Daily  Return_t-1  \\\n",
            "0  2010 -0.002867     0.23301           NaN           NaN         NaN   \n",
            "1  2010 -0.008010     0.23301           NaN     -0.010863   -0.002867   \n",
            "2  2010  0.000000     0.23301           NaN     -0.003553   -0.008010   \n",
            "3  2010  0.000975     0.23301           NaN     -0.001297    0.000000   \n",
            "4  2010  0.005222     0.23301      0.077859     -0.000324    0.000975   \n",
            "\n",
            "   Return_t-2  \n",
            "0         NaN  \n",
            "1         NaN  \n",
            "2   -0.002867  \n",
            "3   -0.008010  \n",
            "4    0.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Moving Averages"
      ],
      "metadata": {
        "id": "w7-8UNNnP-4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort by Symbol and Date\n",
        "df = df.sort_values(['Symbol', 'Date']).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "F5xHLtaQB8_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Adding simple moving averages...\")\n",
        "\n",
        "# Moving Averages (5, 10, 20, 50, 200)\n",
        "df['MA_5'] = df.groupby('Symbol')['Close'].transform(\n",
        "    lambda x: x.rolling(window=5, min_periods=1).mean()\n",
        ")\n",
        "\n",
        "df['MA_10'] = df.groupby('Symbol')['Close'].transform(\n",
        "    lambda x: x.rolling(window=10, min_periods=1).mean()\n",
        ")\n",
        "\n",
        "df['MA_20'] = df.groupby('Symbol')['Close'].transform(\n",
        "    lambda x: x.rolling(window=20, min_periods=1).mean()\n",
        ")\n",
        "\n",
        "df['MA_50'] = df.groupby('Symbol')['Close'].transform(\n",
        "    lambda x: x.rolling(window=50, min_periods=1).mean()\n",
        ")\n",
        "\n",
        "df['MA_200'] = df.groupby('Symbol')['Close'].transform(\n",
        "    lambda x: x.rolling(window=200, min_periods=1).mean()\n",
        ")\n",
        "\n",
        "# Price relative to moving averages\n",
        "df['Price_to_MA20'] = df['Close'] / df['MA_20']\n",
        "df['Price_to_MA50'] = df['Close'] / df['MA_50']\n",
        "\n",
        "print(\"Simple Moving averages completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj1fCGqGDv59",
        "outputId": "98de0109-79fe-4732-c776-13e59b9a3b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding simple moving averages...\n",
            "Simple Moving averages completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Report missing values\n",
        "print(\"Missing values after adding Simple Moving Averages (SMA):\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b27fb3d5-85da-4df1-e2b4-edf2cf11f7f1",
        "id": "o85UxkOENaAV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values after adding Simple Moving Averages (SMA):\n",
            "Date                0\n",
            "Symbol              0\n",
            "Open                0\n",
            "High                0\n",
            "Low                 0\n",
            "Close               0\n",
            "Volume              0\n",
            "Year                0\n",
            "Return              0\n",
            "Annual_Vol          0\n",
            "Roll_Vol_30d     1708\n",
            "Return_Daily        1\n",
            "Return_t-1        427\n",
            "Return_t-2        854\n",
            "MA_5                0\n",
            "MA_10               0\n",
            "MA_20               0\n",
            "MA_50               0\n",
            "MA_200              0\n",
            "Price_to_MA20       0\n",
            "Price_to_MA50       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exponential Moving Averages (EMA) â€” reacts faster to price changes\n",
        "df['EMA_12'] = df.groupby('Symbol')['Close'].transform(lambda x: x.ewm(span=12, adjust=False).mean())\n",
        "df['EMA_26'] = df.groupby('Symbol')['Close'].transform(lambda x: x.ewm(span=26, adjust=False).mean())\n"
      ],
      "metadata": {
        "id": "vUmXmNaBGsDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Adding Exponential Moving Averages...\")\n",
        "\n",
        "# Exponential Moving Averages (different timeframes)\n",
        "\n",
        "df['EMA_5'] = df.groupby('Symbol')['Close'].transform(\n",
        "    lambda x: x.ewm(span=5).mean()\n",
        ")\n",
        "\n",
        "df['EMA_10'] = df.groupby('Symbol')['Close'].transform(\n",
        "    lambda x: x.ewm(span=10).mean()\n",
        ")\n",
        "\n",
        "#12-day EMA & 26-day EMA:\n",
        "df['EMA_12'] = df.groupby('Symbol')['Close'].transform(\n",
        "    lambda x: x.ewm(span=12).mean()\n",
        ")\n",
        "\n",
        "df['EMA_20'] = df.groupby('Symbol')['Close'].transform(\n",
        "    lambda x: x.ewm(span=20).mean()\n",
        ")\n",
        "\n",
        "#12-day EMA & 26-day EMA:\n",
        "df['EMA_26'] = df.groupby('Symbol')['Close'].transform(\n",
        "    lambda x: x.ewm(span=26).mean()\n",
        ")\n",
        "\n",
        "# 50-day EMA:\n",
        "df['EMA_50'] = df.groupby('Symbol')['Close'].transform(\n",
        "    lambda x: x.ewm(span=50).mean()\n",
        ")\n",
        "\n",
        "# Price relative to EMAs\n",
        "df['Price_to_EMA10'] = df['Close'] / df['EMA_10']\n",
        "df['Price_to_EMA20'] = df['Close'] / df['EMA_20']\n",
        "df['Price_to_EMA50'] = df['Close'] / df['EMA_50']\n",
        "\n",
        "# EMA crossover signals\n",
        "df['EMA_Cross_5_10'] = df['EMA_5'] - df['EMA_10']\n",
        "df['EMA_Cross_10_20'] = df['EMA_10'] - df['EMA_20']\n",
        "\n",
        "print(\"Exponential Moving Averages, price rations and crossover signals completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXMgVW-SNsIf",
        "outputId": "cd6b1ab0-d39d-47f5-f478-bee0a76ca0b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding Exponential Moving Averages...\n",
            "Exponential Moving Averages, price rations and crossover signals completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Report missing values\n",
        "print(\"Missing values after adding Exp Moving Averages (EMA):\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1f54ee5-ad4e-4e29-d7ee-b9ee978be1fd",
        "id": "EA4O05nKQJtP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values after adding Exp Moving Averages (EMA):\n",
            "Date                  0\n",
            "Symbol                0\n",
            "Open                  0\n",
            "High                  0\n",
            "Low                   0\n",
            "Close                 0\n",
            "Volume                0\n",
            "Year                  0\n",
            "Return                0\n",
            "Annual_Vol            0\n",
            "Roll_Vol_30d       1708\n",
            "Return_Daily          1\n",
            "Return_t-1          427\n",
            "Return_t-2          854\n",
            "MA_5                  0\n",
            "MA_10                 0\n",
            "MA_20                 0\n",
            "MA_50                 0\n",
            "MA_200                0\n",
            "Price_to_MA20         0\n",
            "Price_to_MA50         0\n",
            "EMA_5                 0\n",
            "EMA_10                0\n",
            "EMA_12                0\n",
            "EMA_20                0\n",
            "EMA_26                0\n",
            "EMA_50                0\n",
            "Price_to_EMA10        0\n",
            "Price_to_EMA20        0\n",
            "Price_to_EMA50        0\n",
            "EMA_Cross_5_10        0\n",
            "EMA_Cross_10_20       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Momentum"
      ],
      "metadata": {
        "id": "YjN-rqiEQ2xA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "# MACD (Moving Average Convergence Divergence)\n",
        "\n",
        "print(\"Calculating MACD (using existing EMAs)...\")\n",
        "\n",
        "# MACD (Moving Average Convergence Divergence)\n",
        "df['MACD'] = df['EMA_12'] - df['EMA_26']\n",
        "\n",
        "df['MACD_Signal'] = df.groupby('Symbol')['MACD'].transform(\n",
        "    lambda x: x.ewm(span=9).mean()\n",
        ")\n",
        "\n",
        "df['MACD_Histogram'] = df['MACD'] - df['MACD_Signal']\n",
        "\n",
        "print(\"MACD indicators completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZlLlT4XRmI4",
        "outputId": "c46c7835-a89d-46b4-b73a-977e037a3294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating MACD (using existing EMAs)...\n",
            "MACD indicators completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###########################\n",
        "# RSI\n",
        "\n",
        "print(\"Calculating RSI...\")\n",
        "\n",
        "def calculate_rsi(group, window=14):\n",
        "    \"\"\"Calculate RSI for a price series\"\"\"\n",
        "    delta = group.diff()\n",
        "    gain = delta.where(delta > 0, 0)\n",
        "    loss = -delta.where(delta < 0, 0)\n",
        "\n",
        "    avg_gain = gain.rolling(window=window, min_periods=1).mean()\n",
        "    avg_loss = loss.rolling(window=window, min_periods=1).mean()\n",
        "\n",
        "    rs = avg_gain / avg_loss\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    return rsi\n",
        "\n",
        "df['RSI'] = df.groupby('Symbol')['Close'].transform(calculate_rsi)\n",
        "\n",
        "print(\"RSI calculation completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oM6dq1KSaeZ",
        "outputId": "3ce47491-a4e5-4bd4-b891-417fddd052fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating RSI...\n",
            "RSI calculation completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Report missing values\n",
        "print(\"Missing values after adding Momentum indicators\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5214fa93-9f17-41bd-c664-ec95999f1d12",
        "id": "3nLxwE-OXLll"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values after adding Momentum indicators\n",
            "Date                  0\n",
            "Symbol                0\n",
            "Open                  0\n",
            "High                  0\n",
            "Low                   0\n",
            "Close                 0\n",
            "Volume                0\n",
            "Year                  0\n",
            "Return                0\n",
            "Annual_Vol            0\n",
            "Roll_Vol_30d       1708\n",
            "Return_Daily          1\n",
            "Return_t-1          427\n",
            "Return_t-2          854\n",
            "MA_5                  0\n",
            "MA_10                 0\n",
            "MA_20                 0\n",
            "MA_50                 0\n",
            "MA_200                0\n",
            "Price_to_MA20         0\n",
            "Price_to_MA50         0\n",
            "EMA_5                 0\n",
            "EMA_10                0\n",
            "EMA_12                0\n",
            "EMA_20                0\n",
            "EMA_26                0\n",
            "EMA_50                0\n",
            "Price_to_EMA10        0\n",
            "Price_to_EMA20        0\n",
            "Price_to_EMA50        0\n",
            "EMA_Cross_5_10        0\n",
            "EMA_Cross_10_20       0\n",
            "MACD                  0\n",
            "MACD_Signal           0\n",
            "MACD_Histogram        0\n",
            "RSI                 688\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Volume features"
      ],
      "metadata": {
        "id": "NJH0GKpKY0lx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "print(\"Adding volume features...\")\n",
        "\n",
        "# Volume moving averages\n",
        "df['Volume_MA_10'] = df.groupby('Symbol')['Volume'].transform(\n",
        "    lambda x: x.rolling(window=10, min_periods=1).mean()\n",
        ")\n",
        "\n",
        "df['Volume_MA_30'] = df.groupby('Symbol')['Volume'].transform(\n",
        "    lambda x: x.rolling(window=30, min_periods=5).mean()\n",
        ")\n",
        "\n",
        "# Volume ratios (current volume vs average)\n",
        "df['Volume_Ratio_10d'] = df['Volume'] / df['Volume_MA_10']\n",
        "\n",
        "# Price-Volume relationship\n",
        "df['PV_Trend'] = df['Return'] * np.log(df['Volume'] + 1)  # Adding 1 to avoid log(0)\n",
        "\n",
        "print(\"Volume features completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZmLgh9fWLTI",
        "outputId": "610f1565-7511-42f0-bcf3-c42a12f54515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding volume features...\n",
            "Volume features completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Risk measures"
      ],
      "metadata": {
        "id": "nGJYLGyHZ344"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Define constants\n",
        "ANNUAL_TRADING_DAYS = 252\n",
        "RISK_FREE_RATE_ANNUAL = 0.02  # 2% annualized\n",
        "RISK_FREE_RATE_DAILY = RISK_FREE_RATE_ANNUAL / ANNUAL_TRADING_DAYS  # ~0.0000794\n",
        "\n",
        "# Calculate rolling 252-day Sharpe Ratio\n",
        "def calculate_sharpe(group):\n",
        "    # rolling mean return (252d)\n",
        "    mean_return = group['Return'].rolling(window=ANNUAL_TRADING_DAYS, min_periods=20).mean()\n",
        "    # rolling standard deviation of return (252d)\n",
        "    std_return = group['Return'].rolling(window=ANNUAL_TRADING_DAYS, min_periods=20).std()\n",
        "    # Sharpe Ratio: (Mean Return - Risk-Free Rate) / Std Return\n",
        "    sharpe = (mean_return - RISK_FREE_RATE_DAILY) / std_return\n",
        "    return sharpe\n",
        "\n",
        "# Apply to each stock\n",
        "df['Sharpe_252d'] = df.groupby('Symbol').apply(calculate_sharpe, include_groups=False).reset_index(drop=True)\n",
        "\n",
        "# Verify no missing values\n",
        "print(\"Missing values after adding Sharpe_252d:\")\n",
        "print(df.isna().sum())\n",
        "\n",
        "# Summary of Sharpe_252d\n",
        "print(\"\\nSharpe_252d summary:\")\n",
        "print(df['Sharpe_252d'].describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtdEYXUGb2ua",
        "outputId": "5cd311a5-310e-4e7c-dd1e-d992c79b82d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values after adding Sharpe_252d:\n",
            "Date                   0\n",
            "Symbol                 0\n",
            "Open                   0\n",
            "High                   0\n",
            "Low                    0\n",
            "Close                  0\n",
            "Volume                 0\n",
            "Year                   0\n",
            "Return                 0\n",
            "Annual_Vol             0\n",
            "Roll_Vol_30d        1708\n",
            "Return_Daily           1\n",
            "Return_t-1           427\n",
            "Return_t-2           854\n",
            "MA_5                   0\n",
            "MA_10                  0\n",
            "MA_20                  0\n",
            "MA_50                  0\n",
            "MA_200                 0\n",
            "Price_to_MA20          0\n",
            "Price_to_MA50          0\n",
            "EMA_5                  0\n",
            "EMA_10                 0\n",
            "EMA_12                 0\n",
            "EMA_20                 0\n",
            "EMA_26                 0\n",
            "EMA_50                 0\n",
            "Price_to_EMA10         0\n",
            "Price_to_EMA20         0\n",
            "Price_to_EMA50         0\n",
            "EMA_Cross_5_10         0\n",
            "EMA_Cross_10_20        0\n",
            "MACD                   0\n",
            "MACD_Signal            0\n",
            "MACD_Histogram         0\n",
            "RSI                  688\n",
            "Volume_MA_10           0\n",
            "Volume_MA_30        1708\n",
            "Volume_Ratio_10d     413\n",
            "PV_Trend               0\n",
            "Sharpe_252d         8113\n",
            "dtype: int64\n",
            "\n",
            "Sharpe_252d summary:\n",
            "count    1.671705e+06\n",
            "mean             -inf\n",
            "std               NaN\n",
            "min              -inf\n",
            "25%     -2.063739e-02\n",
            "50%      1.917818e-02\n",
            "75%      5.917588e-02\n",
            "max      5.049099e-01\n",
            "Name: Sharpe_252d, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Join Sector/Company data:"
      ],
      "metadata": {
        "id": "M4_6Q6Lleaur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load from uploaded file\n",
        "companies = pd.read_csv('/content/sp500_companies.csv')\n",
        "\n",
        "\n",
        "# Verify loading\n",
        "print(companies.head())\n",
        "print(companies.columns)\n",
        "print(f\"Unique symbols: {companies['Symbol'].nunique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hrQ0Qycpjua",
        "outputId": "e99ed652-e7ef-4d18-8525-d13aa411cf36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Exchange Symbol              Shortname               Longname  \\\n",
            "0      NMS   AAPL             Apple Inc.             Apple Inc.   \n",
            "1      NMS   NVDA     NVIDIA Corporation     NVIDIA Corporation   \n",
            "2      NMS   MSFT  Microsoft Corporation  Microsoft Corporation   \n",
            "3      NMS   AMZN       Amazon.com, Inc.       Amazon.com, Inc.   \n",
            "4      NMS  GOOGL          Alphabet Inc.          Alphabet Inc.   \n",
            "\n",
            "                   Sector                        Industry  Currentprice  \\\n",
            "0              Technology            Consumer Electronics        254.49   \n",
            "1              Technology                  Semiconductors        134.70   \n",
            "2              Technology       Software - Infrastructure        436.60   \n",
            "3       Consumer Cyclical                 Internet Retail        224.92   \n",
            "4  Communication Services  Internet Content & Information        191.41   \n",
            "\n",
            "       Marketcap        Ebitda  Revenuegrowth           City State  \\\n",
            "0  3846819807232  1.346610e+11          0.061      Cupertino    CA   \n",
            "1  3298803056640  6.118400e+10          1.224    Santa Clara    CA   \n",
            "2  3246068596736  1.365520e+11          0.160        Redmond    WA   \n",
            "3  2365033807872  1.115830e+11          0.110        Seattle    WA   \n",
            "4  2351625142272  1.234700e+11          0.151  Mountain View    CA   \n",
            "\n",
            "         Country  Fulltimeemployees  \\\n",
            "0  United States           164000.0   \n",
            "1  United States            29600.0   \n",
            "2  United States           228000.0   \n",
            "3  United States          1551000.0   \n",
            "4  United States           181269.0   \n",
            "\n",
            "                                 Longbusinesssummary    Weight  \n",
            "0  Apple Inc. designs, manufactures, and markets ...  0.069209  \n",
            "1  NVIDIA Corporation provides graphics and compu...  0.059350  \n",
            "2  Microsoft Corporation develops and supports so...  0.058401  \n",
            "3  Amazon.com, Inc. engages in the retail sale of...  0.042550  \n",
            "4  Alphabet Inc. offers various products and plat...  0.042309  \n",
            "Index(['Exchange', 'Symbol', 'Shortname', 'Longname', 'Sector', 'Industry',\n",
            "       'Currentprice', 'Marketcap', 'Ebitda', 'Revenuegrowth', 'City', 'State',\n",
            "       'Country', 'Fulltimeemployees', 'Longbusinesssummary', 'Weight'],\n",
            "      dtype='object')\n",
            "Unique symbols: 502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#join sector/company data\n",
        "df = df.merge(companies[['Symbol', 'Sector', 'Industry', 'Longname']], on='Symbol', how='left')\n",
        "\n",
        "# Verify no missing values\n",
        "print(\"Missing values after adding Sharpe_252d:\")\n",
        "print(df.isna().sum())"
      ],
      "metadata": {
        "id": "LhaB9FhKGE2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e3fdb22-5a9a-4422-8eb3-39ee7cff325b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values after adding Sharpe_252d:\n",
            "Date                   0\n",
            "Symbol                 0\n",
            "Open                   0\n",
            "High                   0\n",
            "Low                    0\n",
            "Close                  0\n",
            "Volume                 0\n",
            "Year                   0\n",
            "Return                 0\n",
            "Annual_Vol             0\n",
            "Roll_Vol_30d        1708\n",
            "Return_Daily           1\n",
            "Return_t-1           427\n",
            "Return_t-2           854\n",
            "MA_5                   0\n",
            "MA_10                  0\n",
            "MA_20                  0\n",
            "MA_50                  0\n",
            "MA_200                 0\n",
            "Price_to_MA20          0\n",
            "Price_to_MA50          0\n",
            "EMA_5                  0\n",
            "EMA_10                 0\n",
            "EMA_12                 0\n",
            "EMA_20                 0\n",
            "EMA_26                 0\n",
            "EMA_50                 0\n",
            "Price_to_EMA10         0\n",
            "Price_to_EMA20         0\n",
            "Price_to_EMA50         0\n",
            "EMA_Cross_5_10         0\n",
            "EMA_Cross_10_20        0\n",
            "MACD                   0\n",
            "MACD_Signal            0\n",
            "MACD_Histogram         0\n",
            "RSI                  688\n",
            "Volume_MA_10           0\n",
            "Volume_MA_30        1708\n",
            "Volume_Ratio_10d     413\n",
            "PV_Trend               0\n",
            "Sharpe_252d         8113\n",
            "Sector                 0\n",
            "Industry               0\n",
            "Longname               0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Target/Y - column"
      ],
      "metadata": {
        "id": "6yY6-k1It3Cz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################\n",
        "# create target\n",
        "\n",
        "# sort by Symbol and Date\n",
        "df = df.sort_values(by=[\"Symbol\", \"Date\"])\n",
        "\n",
        "# Target: Next-Day Return (Regression)\n",
        "# percentage chg from the close of the current day (T) to the close of the next day (T+1)\n",
        "df[\"Target_Return_Next_Day\"] = df.groupby(\"Symbol\")[\"Close\"].pct_change().shift(-1)\n",
        "\n",
        "# Target: Price Direction (Classification)\n",
        "# 1 if the next day's return is positive, 0 otherwise.\n",
        "df[\"Target_Direction_Next_Day\"] = (df[\"Target_Return_Next_Day\"] > 0).astype(int)\n",
        "\n",
        "# Target: Next-Week Return (Multi-period Regression)\n",
        "# percentage chg from the close of the current day (T) to the close 5 days in the future (T+5)\n",
        "df[\"Target_Return_Next_Week\"] = df.groupby(\"Symbol\")[\"Close\"].pct_change(periods=5).shift(-5)\n",
        "\n",
        "# Clean up rows where targets cannot be calculated\n",
        "# This will be the last 5 rows for each symbol, as they lack future data for the weekly target.\n",
        "df = df.dropna(subset=[\"Target_Return_Next_Day\", \"Target_Return_Next_Week\"])\n",
        "\n",
        "# --- Display the results ---\n",
        "print(\"Generated Targets:\")\n",
        "print(df[[\"Symbol\", \"Date\", \"Close\", \"Target_Return_Next_Day\", \"Target_Direction_Next_Day\", \"Target_Return_Next_Week\"]].head(10))\n",
        "\n",
        "print(\"\\nLast few rows for a sample symbol to show NaN drop:\")\n",
        "print(df[df[\"Symbol\"] == \"AAPL\"][[\"Symbol\", \"Date\", \"Close\", \"Target_Return_Next_Day\", \"Target_Return_Next_Week\"]].tail(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jp7sqNsMWMNJ",
        "outputId": "0b2e66b7-0c0c-476c-9520-74656fe6ca37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Targets:\n",
            "  Symbol       Date      Close  Target_Return_Next_Day  \\\n",
            "0      A 2010-01-04  19.931625               -0.010863   \n",
            "1      A 2010-01-05  19.715115               -0.003553   \n",
            "2      A 2010-01-06  19.645065               -0.001297   \n",
            "3      A 2010-01-07  19.619591               -0.000324   \n",
            "4      A 2010-01-08  19.613228                0.000649   \n",
            "5      A 2010-01-11  19.625954               -0.012005   \n",
            "6      A 2010-01-12  19.390343                0.007882   \n",
            "7      A 2010-01-13  19.543177                0.014989   \n",
            "8      A 2010-01-14  19.836102               -0.023114   \n",
            "9      A 2010-01-15  19.377609                0.012159   \n",
            "\n",
            "   Target_Direction_Next_Day  Target_Return_Next_Week  \n",
            "0                          0                -0.015336  \n",
            "1                          0                -0.016473  \n",
            "2                          0                -0.005186  \n",
            "3                          0                 0.011035  \n",
            "4                          1                -0.012013  \n",
            "5                          0                -0.000648  \n",
            "6                          1                 0.005911  \n",
            "7                          1                -0.005539  \n",
            "8                          0                -0.063564  \n",
            "9                          1                -0.032205  \n",
            "\n",
            "Last few rows for a sample symbol to show NaN drop:\n",
            "     Symbol       Date       Close  Target_Return_Next_Day  \\\n",
            "7853   AAPL 2025-08-04  203.119492               -0.002115   \n",
            "7854   AAPL 2025-08-05  202.689957                0.050907   \n",
            "7855   AAPL 2025-08-06  213.008255                0.031794   \n",
            "7856   AAPL 2025-08-07  219.780563                0.042358   \n",
            "7857   AAPL 2025-08-08  229.090012               -0.008337   \n",
            "7858   AAPL 2025-08-11  227.179993                0.010872   \n",
            "7859   AAPL 2025-08-12  229.649994                0.016024   \n",
            "7860   AAPL 2025-08-13  233.330002               -0.002357   \n",
            "7861   AAPL 2025-08-14  232.779999               -0.005112   \n",
            "7862   AAPL 2025-08-15  231.589996               -0.003023   \n",
            "\n",
            "      Target_Return_Next_Week  \n",
            "7853                 0.118455  \n",
            "7854                 0.133011  \n",
            "7855                 0.095404  \n",
            "7856                 0.059147  \n",
            "7857                 0.010913  \n",
            "7858                 0.016331  \n",
            "7859                 0.003963  \n",
            "7860                -0.031372  \n",
            "7861                -0.033852  \n",
            "7862                -0.016538  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Final file"
      ],
      "metadata": {
        "id": "nLgYkN5qvSwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save dataset\n",
        "df.to_csv('/content/drive/MyDrive/sp500_stocks_feature-eng.csv', index=False)\n"
      ],
      "metadata": {
        "id": "Lg7fHBs4vWlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y4Uyvfx1vYlR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}